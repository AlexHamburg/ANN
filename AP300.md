
Inhaltsverzeichnis
==================

[1 Gesamtkonzeption](#1)  
[1.1 MISSION-Infrastruktur](#1.1)  
[1.2 Routing und Events](#1.2)  
[1.2.1 Das gesamte MISSION System: Überblick](#1.2.1)  
[1.2.2 Routing Service: statische Sichtweise](#1.2.2)  
[1.2.2.1 Definition und Aufgaben des Service](#1.2.2.1)  
[1.2.2.2 Architektur des Service](#1.2.2.2)  
[1.2.2.3 Graphendatenbank Neo4j als Basis des Service](#1.2.2.3)  
[1.2.2.4 Position des Routing Service im gesamten MISSION System](#1.2.2.4)  
[1.2.3 Service Events: statische Sichtweise](#1.2.3)  
[1.2.3.1 Definition und Aufgaben des Services](#1.2.3.1)  
[1.2.3.2 Architektur des Services](#1.2.3.2)  
[1.2.3.3 Event Store als Basis des Services](#1.2.3.3)  
[1.2.3.4 Position des Event Service im gesamten MISSION System](#1.2.3.4)  
[1.2.4 Funktionale und non-funktionale Anforderungen an MISSION System](#1.2.4)  
[1.2.4.1 Anforderungen an den Routing Service](#1.2.4.1)  
[1.2.4.2 Anforderungen an die Event Services](#1.2.4.2)  
[1.3 Anwendungen](#1.3)  
[1.4 Zusammenspiel der Komponenten](#1.4)  
[1.4.1 Dienste werden in Infrastruktur registriert](#1.4.1)  
[1.4.2 Anwendungen finden Dienste über Infrastruktur](#1.4.2)  
[1.4.3 Anwendungen nutzen Dienste](#1.4.3)  

Abkürzungsverzeichnis
=====================

|Abkürzung  |Bedeutung                                  |
|-----------|-------------------------------------------|
|**API**    |Anwendungsprogrammierschnittstelle         |
|**BRG**    |Baltic Rail Gate GmbH                      |
|**Bode**   |Spedition Bode GmbH & CO. KG               |
|**CSV**    |Comma-separated values                     |
|**CQRS**	|Command-Query-Resposibility-Segregation    |
|**DDD**	|Domain-driven Design                       |
|**ECL**	|European Cargo Logistics GmbH              |
|**ETL**	|Extraction, Transformation, Laden          |
|**GTFS**	|General Transit Feed Specification         |
|**I/O**	|Input / Output                             |
|**LPG**	|Label-Property Graphendatenbank            |
|**NoSQL**	|Nicht nur SQL Datenbanktechnologien        |
|**RDBMS**	|Relational Datenbankmanagementsystem       |
|**RDF**	|Resource Description Framework             |
|**SQL**	|Structured Query Language                  |

<h1 id="1"> 1 Gesamtkonzeption </h1>
<h2 id="1.1"> 1.1 MISSION-Infrastruktur </h2>
<h2 id="1.2"> 1.2 Routing und Events </h2>
<h3 id="1.2.1"> 1.2.1 Das gesamte MISSION System: Überblick </h3>
Aus funktionaler Sicht kann das MISSION-System, welches in Abbildung 1 dargestellt ist, in zwei Hauptbestandteile aufgeteilt werden, da sie für unterschiedliche funktionale Bereiche verantwortlich sind:  
* MISSION Infrastruktur  
* MISSION Zentralsystem.    

Die MISSION Infrastruktur ist grundsätzlich für Identitäts- und Anwendungs- bzw. Serviceregister zuständig und soll eine möglichst dezentrale, diskriminierungsfreie und erweiterbare Realisierung des Systems ermöglichen. Das MISSION Zentralsystem soll Angebots-, Informations- und Eventsdarstellung, Routenvermittlung und Optimierung sowie die Eventverarbeitung realisieren.  

Deshalb ist es möglich das MISSION Zentralsystem konzeptionell in zwei Teile aufzuteilen:  
* Front-End (Applikation  Angebots- und Eventdarstellung), welches näher im [Kapitel 1.3](#1.3) beschrieben wird.  
* Back-End (Services Routing und Events), welches in diesem [Kapitel 1.2](#1.2) beschrieben wird.  

Das Back-End steht im Fokus dieses Kapitels und besteht aus zwei Services: Routing und Events, welche im Rahmen des Dokumentes beschrieben werden.  

Die gesamte Architektur des Systems ist serviceorientiert, modularisiert und verteilt. Das bedeutet, dass die Dienstleistungen der einzelnen Komponenten als Services realisiert werden und das System somit dezentralisiert ist (es befindet sich gleichzeitig auf mehreren Hardwares).  

Die beschriebene Struktur und IT-Architektur sichert die lose Kopplung und erhöht die Kohäsion der Komponenten des MISSION Systems. Erhöhte Wartbarkeit, Skalierbarkeit und Wiederverwendbarkeit des gesamten Systems, sind die Ziele, die mit den aufgelisteten Merkmalen erreicht werden sollen. Außerdem erlaubt die serviceorientierte Architektur eine hohe Unabhängigkeit der an MISSION angeschlossenen fremden Systeme, was dazu führt, dass sowohl der Zeit-, als auch der Kostenaufwand reduziert <sup>[1](#myfootnote1)</sup> werden.  

<h3 id="1.2.2"> 1.2.2	Routing Service: statische Sichtweise </h3>

In diesem Kapitel wird der Routing Service aus einer statischen Sicht betrachtet. Das bedeutet, dass die Struktur und die einzelnen Komponenten definiert werden. Darüber hinaus werden mögliche Technologien, die zu der praktischen Realisation führen, aus fachlicher Perspektive betrachtet und evaluiert. Des Weiteren wird die Position der Routing Komponente im MISSION System bestimmt und die internen Kanäle zum Austausch von Daten, die für das Routing relevant sind, beschrieben. Dieses Kapitel dient als Grundlage und Sollvorgabe für künftige Arbeitspakete.

<h4 id="1.2.2.1">  1.2.2.1	Definition und Aufgaben des Service </h4>

Die Hauptziele des Konzeptes Routing basieren auf den im Folgenden genannten Kernaufgaben des Routing Services. Zunächst handelt es sich um die Abholung der Fahrpläne bei registrierten Unternehmen bzw. Serviceanbietern. Dieser Prozess soll mittels des Pull-Prinzips realisiert werden (siehe Abbildung 2). Das bedeutet, dass es im Aufgabenbereich des Routing Services liegt die Fahrpläne bei den beteiligten Unternehmen abzuholen. Außerdem soll aufgrund dieses Pull-Prinzips der Routing Service in der Lage sein rechtzeitig Änderungen von Fahrplänen zu identifizieren und zu übernehmen.

Die Fahrpläne und die Änderungen der Fahrpläne sollen in vordefinierten Formaten von beteiligten Unternehmen vorbereitet und bereitgestellt werden. Das heißt es liegt nicht im Aufgabenbereich der Routing Komponente einen Fahrplanformat-Konverter zu realisieren. Die Verantwortung der Einhaltung der Fahrplanformate, liegt auf der Seite der an MISSION angeschlossenen Teilnehmer.

Es existieren zwei Ansätze den Prozess der Fahrplanaktualisierung zu realisieren. Zum einen ist es möglich die gesamten veränderten Fahrpläne jedes Mal abzuholen. Zum anderen besteht die Möglichkeit den genannten Aktualisierungsprozess mithilfe der vordefinierten Events zu realisieren und schließlich nur die geänderten Daten abzuholen. Diese beiden Ansätze werden im Rah-men dieses Kapitels detaillierter betrachtet.

Ein wesentliches Ziel des Routings ist die zuverlässige Berechnung des Transportplans unter Berücksichtigung von diversen Bedingungen, welche der Benutzer dem als Input liefert. Unter Bedingungen werden alle, für die Transportplanberechnung relevanten Daten verstanden. Dazu gehören ebenfalls Versanddatum sowie Versands- und Empfangsorte, die als konkrete Städte oder möglicherweise Terminale durch die Applikation Angebotsdarstellung vom Benutzer eingegeben werden müssen. Die konkreten Pflichteingaben, um das Service Routenberechnung zu nutzen, werden in diesem Dokument betrachtet und werden in der Abbildung 3 dargestellt.

Neben den Start- und Zielorten soll der Routing Service auch andere optionale Bedingungen bei der Routenberechnung berücksichtigen (ebenfalls in Abbildung 3 exemplarisch dargestellt). Dazu gehören beispielsweise der umweltfreundliche Transport, der kürzeste Weg oder auch andere Varianten, die vom Benutzer eingegeben werden können. Einen Ablauf wie die Eingabe der Daten erfolgt ist der Abbildung 4 zu entnehmen, hierbei werden Prozesse der Authentifizierung und Servicesuche nicht berücksichtigt, da der Ablauf zwischen Benutzereingaben und Transportplanerstellung an sich im Fokus liegt (ein detaillierter Ablauf wird im weiteren Verlauf skizziert).

Der Routing Service soll auch Informationen über die beteiligten Unternehmen in den vorgeschlagenen Transportplänen anbieten. Unter den genannten Informationen sind die Daten gemeint, die für die Kontaktaufnahme mit den in der Transportkette beteiligten Unternehmen essentiell sind. Die Darstellung des verbindlichen Angebots und der konkreten Preise wird, auf der aktuellen Etappe des MISSION Projektes, vorerst nicht als konkretes Ziel des Konzeptes Routing betrachtet. Auf den weiteren Entwicklungsetappen des MISSION Systems ist es bei Bedarf möglich die Preise (insofern diese vorliegen) oder andere erforderliche Information aufgrund der serviceorientierten Architektur ohne großen Aufwendungen zu implementieren.

<h4 id="1.2.2.2"> 1.2.2.2	Architektur des Service </h4>

Die im vorherigen Abschnitt definierten Aufgaben dienen als Fundament für die Bestimmung und Definition der Komponenten des Routing Services. Eine aufgaben- und prozessorientierte Architektur bietet mehrere Vorteile, dazu gehören unter anderem die erhöhte Wartbarkeit <sup>[2](#myfootnote2)</sup> und die verständliche Struktur des Services. Außerdem führt diese Struktur zur losen Kopplung der einzelnen Bestandteile des Services, welches zur Erhöhung der Qualität des Systems beiträgt.

Grundsätzlich ist es möglich zwei Kernaufgaben des Services zu definieren:
* die Routenberechnung und
* die Routen(Fahrplan-)Aktualisierung.

Diese stellen die zwei wichtigen Kernkomponenten des Routing Services dar: Die Routing Komponente und die Komponente Routenupdates (siehe Abbildung 5). Eine weitere wichtige Komponente ist die interne API, die für den I/O (Input / Output) Bereich des Services verantwortlich ist und die Daten (z. B. die Liste mit berechneten Routen) für die weiteren Komponenten des MISSION Systems (z. B. für die Applikation Angebotsdarstellung) vorbereitet.

Die Routing Komponente des Routing Services bildet die Anwendungslogik des gesamten Services ab. Die Berechnung der Routen (dargestellt in Abbildung 6) basiert auf den vorhandenen Fahrplänen, die von den, in MISSION registrierten, Service-Anbietern zur Verfügung gestellt wurden. Des Weiteren erfolgt die Routenberechnung unter Berücksichtigung von definierter Bedingungen, welche der Benutzer angibt.

Technisch gesehen bietet dieser Teil der Anwendung den Routing Service an. Dieser Teil des Services, der als der Knotenpunkt des Services dient, verbindet und koordiniert die anderen Komponenten des Services (inkl. des persistenten Teils des MISSION Systems).

Die Routingupdate Komponente des Routing Services ist für die Aktualisierung der im System vorhandenen Fahrpläne verantwortlich. Diese Aktualisierung soll in nahe Echtzeit erfolgen, damit die Aktualität der Daten gewährleistet werden kann. Die Fahrplanbeschaffung und die Fahrplanaktualisierung sollen mittels des, bereits in Abschnitt 1.2.2.1 beschriebenen, Pull-Prinzips umgesetzt werden. Aus diesem Grund muss die Routingupdate Komponente die Aktualität der Fahrpläne in vordefinierten zeitlichen Intervallen prüfen und bei Bedarf initiativ, mittels eines entsprechenden Services, neue Fahrplan-Versionen bei den Anbietern abholen und einbinden. Bei den Versionen kann es sich, wie bereits beschrieben, um gänzlich neue Fahrpläne oder lediglich um einzelne Änderungen des Fahrplans handeln.

<h4 id="1.2.2.3"> 1.2.2.3	Graphendatenbank Neo4j als Basis des Service </h4>

Als Lösung für die Fahrplanspeicherung und -Verwaltung fiel die Wahl auf die Neo4j Datenbank <sup>[3](#myfootnote3)</sup> . Diese wird als Graphdatenbank realisiert, das bedeutet, dass die Daten (werden als Knoten betrachtet) als ein Graph mit ihren Beziehungen (werden als Kanten betrachtet) gespeichert werden.

Mehrere Gründe und Argumente bestärken die Wahl von Neo4j. Zunächst stellen die Routenberechnungen grundsätzlich das Problem aus der Graphentheorie dar. Gleichzeitig bietet Neo4j damit die Ansicht von Daten als Graph an. Folglich bildet die Neo4j Datenbank die logische und physische Struktur des Problems der Routenberechnung realitätsnah und intuitiv ab. Das führt zu einer effizienten Problemerfassung ohne zusätzlichen Zeitaufwand sowie zu einer Kostenreduzierung <sup>[4](#myfootnote4)</sup>, bei der Instandhaltung und Wartung der Datenbank. Eine solche Darstellung der Daten kann auch als ein Vorteil, im Vergleich zu anderen NoSQL Datenbankstrukturen, im Fall der Routenberechnung betrachtet werden, da die Graphdatenbank eine höhere Leistung in der Arbeit mit den hochvernetzten Daten <sup>[5](#myfootnote5)</sup>, was gerade die Fahrpläne darstellen, anbietet. Unter anderen NoSQL Datenbankstrukturen sind Dokumentdatenbanken, Schlüssel-Werte-Datenbanken und Spaltenorientierte Datenbanksystemen zu verstehen.

Im Gegensatz zu traditionellen RDBMS (Relational Database Management System) speichert eine Graphdatenbank explizit die Beziehungen zwischen den Daten (siehe Abbildung 7). Das führt dazu, dass der Bedarf an der Durchführung von JOIN Operationen wegfällt. In der Graphdatenbank ist es möglich die Daten und Beziehungen sofort zu bearbeiten. Gleichzeitig erlaubt die Neo4j Datenbank die Suche, Auswahl sowie andere Operationen aufgrund der Datenklassen, Beziehungstypen und ihren Attributen, direkt ohne Zwischenschritte wie JOIN in SQL durchzuführen. Als Folge wird die Effizienz der Anfrage und Selektierung stark erhöht und die Komplexität reduziert. Folgendes Beispiel verdeutlicht dieses: Es wurde angenommen, dass in einem RDBMS - wie es in der Abbildung 7 dargestellt ist - zwei Tabellen mit Daten über die Logistikunternehmen und mit Informationen über die Abfahrts- und Ankunftstage existieren. Um eine Übersicht zu schaffen, wer und an welchen Tagen transportiert, soll die SQL JOIN-Operation durchgeführt werden. Als Folge handelt es sich im schlechtesten Fall um die quadratische Komplexität __(O(|S|x|P|)__, wobei __„S“__ die Menge von Zeilen aus der ersten Tabelle „Transportunternehmen“ darstellt und __„P“__ ist die Menge von Zeilen aus der zweiten Tabelle „Routen“). Die Suche nach den Verbindungen zwischen Daten in der Graphendatenbank wie Neo4j dagegen, hat eine lineare Komplexität __(O(n))__.

Außerdem bietet die Neo4j Datenbank eine flexible Struktur an. Im Vergleich zu traditionellen Lösungen in Form von RDBMS besitzt die Neo4j Datenbank keine feste Struktur und erlaubt somit eine ständige schrittweise Weiterentwicklung des Systems. Als Folge verfügt die Neo4j Datenbank über eine hohe vertikale und horizontale Skalierbarkeit. Das erleichtert den gesamten Entwicklungsprozess und die Anpassung des Systems an neue Bedürfnisse, Formate und Struk-turen der neuen an das MISSION-Projekt angeschlossenen Partnern.

Ein weiterer wichtiger Vorteil von der Neo4j Datenbank zu anderen Datenbankmodellen ist die Verfügbarkeit von mehreren APIs sowie einfache Dateiformate wie beispielsweise CSV. Dies wurde durch den eingebauten Extraction, Transormation, Laden (kurz: ETL) erreicht. Zusätzlich unterstützt die Neo4j Datenbank mehrere Programmiersprachen wie Java, JavaScript, Python, .Net, usw. bei der Integration<sup>[6](#myfootnote6)</sup>.

Darüber hinaus ist die CommunityEdition der Neo4j Datenbank unter General Public License (GPL) v3 lizensiert, das bedeutet, dass die Neo4j Datenbank kostenlos und unbegrenzt ausgeführt, studiert und geändert werden kann, was zur Kostensenkung bei der Implementierung und Verwendung im MISSION Projekt führt. Dieser Punkt kann auch als ein Vorteil im Vergleich zu anderen Graphdatenbanken wie IBM Graph <sup>[7](#myfootnote7)</sup> gesehen werden.

Im Vergleich zu anderen Typen von Graphdatenbanken ist die Neo4j Datenbank eine LabelProperty Graphendatenbank (LPG) <sup>[8](#myfootnote8)</sup>. Das bedeutet, dass die Knoten und die Kanten im Graph die Label, den Typ der Knoten oder die Beziehung repräsentieren, und die Properties im Form von Schlüssel-Wert-Paaren haben können. Dieses Schema bietet mehrere Vorteile im Vergleich zu anderen Typen der Graphendatenbanken. Neo4j erlaubt die mehrfache Erstellung und Speicherung der Beziehungen des gleichen Typs zwischen den gleichen Knoten. Im Vergleich ist es bei einer Ressource Description Framework (RDF) Datenbank <sup>[9](#myfootnote9)</sup> nicht erlaubt die Beziehungen (Kanten) durch Attribute (Properties bei LPG) direkt zu qualifizieren, sodass es nicht möglich ist die gleichen Beziehungen (des gleichen Typs) zwischen zwei Knoten zu erstellen (Abbildung 8). Aus diesem Grund würden RDF Datenbanken sich für die Routenberechnungen nicht eignen.

Ein weiteres Model der Graphendatenbank ist der Hypergraph. Im Vergleich zur LPG kann ein Hypergraph die Beziehungen, die gleichzeitig mehrere Kanten verbinden, enthalten. Gleichzeitig kann eine Kante in der LPG nur zwei Knoten verbinden <sup>[10](#myfootnote10)</sup> (Abbildung 9). Im Rahmen des MISSION Projekts entsteht kein expliziter Bedarf an der Modellierung der Beziehungen, die mehrere Knoten verbinden. Allerdings ist es immer möglich die genannte Art von Beziehungen durch Attribute von Kanten mit Priorisierung von Beziehungen zu modellieren.

Die explizite Speicherung von Daten und die Beziehungen zwischen den Daten bieten eine höhere Geschwindigkeit bei den Berechnungen und ermöglichen Echtzeit-Routenberechnung. Außerdem wird dadurch auch der Bedarf an Rechnerleistung im Vergleich zu Berechnungen im RDBMS verringert, weil z. B. die komplexen SQL-JOIN-Berechnungen unnötig sind.
Gleichzeitig entsteht ein höherer Bedarf an Speicherkapazitäten, aufgrund der expliziten Spei-cherung von Beziehungen zwischen den Daten, welches aber durch die Echtzeit-Routenberechnung kompensiert wird.

Es ist auch wichtig zu erwähnen, dass Neo4j aufgrund der dynamischen Datenkompression (verlustfreier Datenkompressionsalgorithmus) die Speicherung und Verwaltung <sup>[11](#myfootnote11)</sup> der Graphen in einer beliebigen Größe erlaubt.

Die extra für Graphdatenbanken entwickelte Anfragesprache Cypher <sup>[12](#myfootnote12)</sup>, die auf stark verbreiteten Anfrage- und Programmiersprachen wie SQL und Python beruht, führt zu einer effizienten und verständlichen Entwicklung sowie Ausführung der Neo4j Datenbank.

Als Zwischenfazit ist es möglich zu sagen, dass die Graphendatenbank, im Vergleich zu den traditionellen RDBMS sowie den anderen NoSQL Datenbanken, speziell für die performante und effiziente Bearbeitung der vernetzten Daten entwickelt wurde. Weiterführend stellen die Routingverarbeitung und Routingplanung das typische Problem aus der Graphentheorie dar, in dem Beziehungen zwischen Knoten eine höhere Wichtigkeit als die Knoten selbst haben. Als Resultat des Vergleichs anderer Graphdatenbanken-Modellen (siehe Abbildung 10), ist das Label-Property Modell der Neo4j Datenbank für die Anforderungen des Routing Services, im Rahmen des MISSION Projekts, geeigneter.

<h4 id="1.2.2.4"> 1.2.2.4	Position des Routing Service im gesamten MISSION System </h4>

Um eine erfolgreiche Integration des Routing Services in das MISSION Gesamtsystem garantieren zu können, ist es notwendig die Position der Routing Komponente in dem Gesamtsystem sowie die Schnittstellen für den Informationsaustausch mit anderen MISSION Systemkomponenten zu identifizieren und zu beschreiben.

Der detaillierten Betrachtung des MISSION Gesamtsystems, welches in Abbildung 1 dargestellt ist, ist zu entnehmen, dass der Routing Service aktiv mit folgenden Komponenten kommuniziert:
* Front-End (Applikation Angebotsdarstellung), 
* MISSION Infrastruktur 
* Event Service.

Diese drei Datenaustauschprozesse spielen eine entscheidende Rolle für die korrekte und effiziente Zusammenarbeit des gesamten Systems sowie für den Routing Service selbst.

Zunächst wird der Datenaustausch mit der Applikation Angebotsdarstellung betrachtet. Unter der genannten Applikation sind die webbasierte Benutzeroberfläche und das Dashboard für LHG zu verstehen. Diese Applikation ermöglicht MISSION Anwendern mit dem System zu interagieren. Die Applikation Angebotsdarstellung wird näher beschrieben in dem [Kapitel 1.3](#1.3) und wird im Folgenden als funktionsfähig und gegeben vorausgesetzt. Unter dieser Voraussetzung wird vom Front-End der Service der Informationssuche (Routing Service) angefragt und die benötigen Steuerungsparameter werden für die Routensuche übermittelt. Diese übermittelten Informationen sind essentiell für die korrekte Funktion des Routing Services. Hierfür muss eine geeignete API für den Informationsaustausch zwischen dem Routing Service und der Angebotsdarstellung entwickelt werden, für die ein einheitliches Datenaustauschformat festgelegt werden muss.

Um diese Informationssuche realisieren zu können wird vorausgesetzt, dass die Services zuvor in der Service-Registry der MISSION Infrastruktur registriert worden sind und identifiziert werden können, sodass der angebotene Service genutzt werden kann. Diese Umsetzung liegt im Aufgabenbereich von Fraunhofer CML und wird ebenfalls als gegeben und funktionsfähig erachtet. Ersichtlich ist, dass beide Komponenten somit auf Basis der Service Registrierung miteinander kommunizieren müssen.

Darüber hinaus wird ebenfalls vorausgesetzt, dass die benannte MISSION Infrastruktur den Routing Service über neue Teilnehmer am MISSION System informiert. Für die Umsetzung dieses Vorgangs spielt der Event Service bereits eine wichtige Rolle, da jede neue Anmeldung in einem entsprechenden Event abgebildet und an den Routing Service übermittelt werden soll. Aufgrund des beschriebenen Events kann die Routenupdate Komponente des Routing Services, die benötigen Vorgänge durchführen und die Services des neuen Anbieters nutzen und einbinden. Die Übermittlung mittels Events soll von der MISSION Infrastruktur durch einen Event Store realisiert werden, der im folgenden [Kapitel 1.2.3](#1.2.3) genauer betrachtet wird.

Wie durch diese Untersuchungen deutlich wird ist, neben der Qualitätssicherung der innerhalb des MISSION Systems zu entwickelten Komponenten, es notwendig ebenso die Datenaustausch und Kommunikationsprozesse zwischen den internen Komponenten zu berücksichtigen und zu konzipieren.

Die entsprechenden Abläufe und Datenaustauschprozesse sowie detaillierte Analyse der Struktur des Routing Services werden detaillierter im Rahmen des AP 310  sowie AP 320 analysiert.
 
<h3 id="1.2.3"> 1.2.3	Service Events: statische Sichtweise </h3>

In diesem Kapitel werden die Struktur und die Bestandteile des Event Services, des MISSION Zentralsystems, erläutert und aus statischer Sicht betrachtet. Neben der internen Architektur der Komponente wird auch dessen Position im gesamten MISSION System definiert.

<h4 id="1.2.3.1"> 1.2.3.1	Definition und Aufgaben des Services </h4>

Gemäß der Vorhabenbeschreibung ist es das Ziel des Event Services die folgenden Informationen bereitzustellen:
* Status zu Verkehrsereignissen der Partner:   
Informationen über Abweichungen des Ist-Transportablaufs vom Soll-Transportablauf
* Status und Detailinformationen zu Transportplänen:  
Fachliche Ereignisse während des Transports (beispielsweise Ankunftszeit des Transportmittels oder Erreichen des Zwischen- oder Umschlagpunktes)

Daraus kann das Hauptziel der Ereignisverarbeitung abgeleitet werden, die entlang der Transportkette auftretenden Events dezentral zu speichern. Diese Speicherung von Events muss gewissen Anforderungen genügen. Die zeitliche Reihenfolge soll gewährleistet sein, das heißt die Werte von einem Event dürfen nicht von einem gleichnamigen weiteren Event überschrieben werden können, und im Allgemeinen soll die Speicherung schreibgeschützt sein, also aufgetretene Events sind nicht veränderbar oder löschbar. Diese Anforderungen erfüllt das Konzept des Event Stores, welcher für die Umsetzung verwendet werden wird. Die Ereignisverarbeitung muss zudem dafür sorgen, dass die Event Stores von den unterschiedlichen Partnern miteinander synchronisiert werden, damit ein verlässlicher Informationsaustausch stattfinden kann.

Da es ein Ziel von MISSION ist, dass Partner selber entscheiden dürfen, welche Informationsdetails an andere Benutzergruppen herausgegeben werden dürfen, ist es auch ein Ziel der Ereignisverarbeitung die Events und die Event Stores der Partner mit Zugriffsrechten zu versehen, damit nicht alle Event Stores oder Events allen Partnern zur Verfügung stehen, falls es nicht gewünscht ist. Des Weiteren muss sichergestellt werden, dass Nutzer nicht in die Event Stores von anderen schreiben können, damit Informationen nicht verfälscht werden.

Der Informationsaustausch erfolgt mittels, dem bereits in früheren [Kapitel 1.2.2.1](#1.2.2.1) beschriebenen, Pull-Verfahrens. Die Ereignisverarbeitung ist also nicht dafür zuständig, ohne konkrete Anfrage von Anwendern, die auftretenden Events aktiv weiterzuleiten (keine Umsetzung des Push-Verfahrens).

Obwohl die oben beschriebenen Anforderungen an die Speicherung der Events im Event Store darauf schließen lassen, dass es anhand dessen möglich ist Analysen, Prognosen und Verhalten abzuleiten, liegen diese nicht im Aufgabenbereich der Ereignisverarbeitung. Ebenso das Ableiten neuer Events von erhaltenen Events ist nicht als Ziel definiert. Solche Funktionalitäten sollen jedoch als zusätzliche Services möglich sein, sodass es ein Ziel ist, für diese eine geeignete Schnittstelle bereitzustellen.

Zusammenfassend sind es die Ziele der Ereignisverarbeitung Events und ein einheitliches Event-Format festzulegen, die dezentrale Speicherung von Events mittels Event Store unter bestimmten Anforderungen umzusetzen, Events zu synchronisieren und die Zugriffsrechte zu berücksichtigen.

<h4 id="1.2.3.2"> 1.2.3.2	Architektur des Services </h4>

Ein wesentlicher Bestandteil der Aufgaben und Anforderungen der Ereignisverarbeitung ist es, verschiedene Events zu veröffentlichen und zu empfangen sowie den Input, in Form eines Event-Typs „Fahrplanaktualisierung“, für die Komponente Routingupdate des Routing Service bereitzustellen. Die Möglichkeit Events zu erzeugen und zu empfangen muss jedem Anbieter, der davon Gebrauch machen möchte, zur Verfügung stehen. Aus diesem Grund und hinsichtlich der vordefinierten Vorgaben, ist es sinnvoll für jeden angeschlossenen Partner und deren System einen dezentralen Event Store einzurichten (eine ausführliche Analyse des Event Stores erfolgt in [1.2.3.3](#1.2.3.3)). In dem jeweiligen Event Store veröffentlicht der Anbieter seine Events mittels des Publish-Prinzips. Bei den Events kann es sich um transportbezogene Events seiner Transportmittel handeln, wie beispielsweise Informationen über Ankunft an oder Abfahrt von einem Ort, Informationen über Verspätungen, oder um Events für die Fahrplanaktualisierung, die sowohl den gesamten neuen Fahrplan als Information enthalten können, als auch lediglich die zu aktualisierenden Routen.

In jedem Event Store soll ein dezentrales Mapping zum bidirektionalen Zugriff oder Abfrage zu den nachgelagerten Anwendungen des angeschlossenen Partners erfolgen. Die Verbindung der Event Stores zum Zentralsystem wird durch das Web Interface realisiert. Der genauere Ablauf von Eventsaustausch, Eventsabonnieren und Synchronisierung wird im Rahmen AP 320 erörtert. Die Komponente Mapping bildet die Schnittstelle zu den individuellen Anwendungen der Anbieter, sodass sie in der Lage sind den Event Service zu nutzen. Diese Schnittstelle muss definiert werden, die Implementierung der Schnittstelle obliegt den Anbietern. Die Komponente Web Interface stellt ein Dashboard dar, auf dem eine Übersicht empfangener und erzeugter Events dargestellt wird.

Des Weiteren soll die Anzahl der zukünftigen Event Stores unbegrenzt sein, sodass beliebig viele Anbieter das MISSION System nutzen und erweitern können. Demnach handelt es sich bei der Event Komponente um eine distributive und dezentrale Architektur. Aus diesen benannten Gründen bietet es sich an, die Komponente der Ereignisverarbeitung in MISSION als Service zu realisieren.

<h4 id="1.2.3.3"> 1.2.3.3	Event Store als Basis des Services </h4>

Als Technologie für die Verarbeitung der Events fiel die Wahl auf den Event Store, welcher von Greg Young entwickelt worden ist. Der Event Store basiert auf dem Event Sourcing Pattern. Das Event Sourcing Pattern ist ein Verfahren in dem jede Änderung des Zustandes einer Applikation in einem Event Objekt festgehalten wird, welches in einer Sequenz gespeichert wird und die Lebensdauer gleich der Lebensdauer der Anwendung selber ist.

Unter dem Event Store kann man sich eine funktionale Datenbank vorstellen, da für Anfragen funktionale Sprachen verwendet werden. Die Zugriffe auf neue oder bereits existierende Events und das Hinzufügen neuer Events basieren auf dem Publish-Subscribe Pattern (siehe Abbildung 12). Ein Publisher ist ein registrierter Anbieter im MISSION System, der einen eigenen Event Store besitzt und Events erzeugt. Subscriber sind registrierte Nutzer oder Anbieter im MISSION System, die an diesen erzeugten Events interessiert sind und diese verfolgen wollen.

Der Event Store grenzt sich von einer regulären Datenbank durch die Eigenschaft ab, dass die Daten in einer Serie von unveränderbaren Events über einen definierten Zeitraum gespeichert werden. Im Falle einer regulären Datenbank würde lediglich der aktuelle Zustand verwaltet werden, also die Daten würden bei Updates überschrieben werden. Da es ein definiertes Ziel von MISSION ist, alle Events über einen gewissen Zeitraum zu speichern, damit es beispielsweise möglich ist zusätzliche Services zu erstellen, die die Events analysieren um Vorhersagen treffen zu können und Verhalten zu bestimmen, damit Prozesse optimiert werden können, ist es notwendig mehr als nur den aktuellen Wert bzw. Zustand des Events zu verwalten. Es sollte also die exakte zeitliche Reihenfolge der Events nachvollziehbar sein und über einen, noch zu definierenden sinnvollen, Zeitraum gespeichert werden. Hinsichtlich der Fairness und der Verifikation der Echtheit der Daten, darf die Reihenfolge nicht modifizierbar sein (um zu verhindern, dass beispielsweise Anbieter Verspätungen löschen um sich besser darzustellen). Diese Funktionalität bietet der Event Store ebenfalls und empfiehlt sich somit als geeignete Lösung um die Ziele von MISSION zu verwirklichen.

Ein weiterer Vorteil des Event Stores liegt darin, dass er in einem Cluster von Knoten laufen kann, welche die gleichen Daten enthalten, sodass der Event Store gut erreichbar ist auch wenn nur die Hälfte der Knoten lebendig sind. Des Weiteren sind so auch die Daten geschützt, falls ein Knoten ausfällt, sind sie nicht verloren.

Der Event Store läuft als ein Server. Um mit diesem kommunizieren zu können, verbindet man sich mit ihm entweder über HTTP oder TCP. Eine TCP - Verbindung bietet sich an, wenn man eine hohe Performance erwartet, es können hiermit 15000 – 20000 Schreibzugriffe pro Sekunde durchgeführt werden. Mit der HTTP – Verbindung können nur 2000 Schreibzugriffe pro Sekunde erfolgen, die Latenz ist demnach höher. Diese Verbindung bietet aber das Caching von Atom Feeds, welche nützlich sind für sich wiederholende Streams. Für MISSION bietet es sich an Events mittels TCP – Verbindung in den Event Store zu schreiben, damit die Performance hoch genug ist bei expandierender Nutzung. Für die Subskription, also dem Abonnieren der Events, bietet sich die HTTP – Verbindung an um die Performance durch Caching zu erhöhen.

Greg Young’s Event Store bietet außerdem zwei Arten der Subskription an (siehe Abbildung 13). Die „Live-Only“ Subskription, welche dem Anwender ab Beginn der Subskription jedes Folgende Event übermittelt (vorherige werden außer Acht gelassen), und die „Catch-Up“ Subskription, bei welcher man angeben kann ab welchem Event man die Events empfangen möchte (hierbei können auch vorherige übermittelt werden).

Es ist nicht möglich nur eine Variante der Subskription für MISSION zu empfehlen, vielmehr ist diese abhängig vom Use Case. Folgende Umsetzung wäre denkbar: Beim Buchen eines Transportablaufes werden die Events der, an der Transportkette beteiligten Akteure, automatisch abonniert. In diesem Falle ist eine „Live Only“ Subskription sinnvoll, weil erst ab diesem Zeitpunkt die Events für die Akteure relevant, bezüglich des Transportablaufs, sind. Da diese Automatisierung aber eventuell nicht für jeden beteiligten Transportakteur von Interesse ist, sollte eine Abfrage vor dem Abonnieren stattfinden, ob dieses überhaupt gewünscht ist, denn nicht jeder beteiligte Akteur interessiert sich für jeden Schritt der Transportkette. Daraus ergibt sich ein weiteres beispielhaftes Szenario: Auf einer Fähre ist ein Truck angemeldet, der noch nicht im Hafen angekommen ist. Die Akteure der Fähre oder des Hafens wollen nun anhand der Events des Trucks feststellen wie groß die Verspätung ist um dann zu entscheiden ob Warten sinnvoll ist oder zu große Auswirkungen hat. Folglich besteht nun doch Interesse die Events der an der Transportkette beteiligten Akteure zu erhalten, sodass sie die Truck Events rückwirkend abonnieren wollen (Voraussetzung hierfür ist, dass der Akteur autorisiert ist die Events zu erhalten). Im Falle einer „Live-Only“ Subskription würden die möglicherweise vorherigen Events nicht einzusehen sein, somit auch nicht die Verspätung, es müsste aktiv auf ein neues Event gewartet werden. Bei einer „Catch-Up“ Subskription allerdings ist es möglich alle vorherigen Events zu empfangen, welche für diesen Use Case essentiell sind. Dieses Szenario ist auch für Anwender von MISSION von Nutzen die nicht aktiv an der Transportkette beteiligt sind, sich aber für Informationen über andere Transportverläufe interessieren, um beispielsweise Slots tauschen zu können. Diese Use Cases zeigen, dass sowohl die „Catch-Up“, als auch die „Live-Only“ Sub-skription des Event Stores sich für die Nutzung von MISSION eigenen.

Darüber hinaus wird im Rahmen des MISSION Projektes eine serviceorientierte Architektur entwickelt und implementiert. Das heißt. die zu implementierenden Services sollen die abstrakte Geschäftslogik abbilden und sich auf die Geschäftsprozesse orientieren. Gleichzeitig bedeutet das, dass das Domain-driver Design (im weiteren Verlauf DDD genannt) bei der Konzeptionierung und Implementierung der einzelnen Komponenten des MISSION Systems eine wichtige Rolle spielt. Ein Event stellt ein fachliches Ereignis dar und ist ein Baustein des DDD. Daraus folgt, dass das Konzept des Event Sourcing und das Konstrukt des Event Stores die Bestandteile von DDD sind. Die gute Übereinstimmung des technischen Hintergrundes des Event Stores mit dem Konzept und dem ausgewählten Design des MISSION Systems wird als ein weiterer Vorteil gesehen.

Bisher wurden nur die Vorteile der Nutzung des Event Stores analysiert, allerdings ergeben sich aus diesen Vorteilen möglicherweise auch Bedenken hinsichtlich Speicherkapazitäten und Performance. Da wie bereits als Vorteil beschrieben, die Ereignisse persistent in einer unveränderlichen zeitlichen Abfolge gespeichert werden, stellt sich hier die Frage ob dadurch Einbußen hinsichtlich des Speichers und der Performance entstehen, denn die Liste mit Events steigt kontinuierlich, was zum einem fortlaufend steigenden Bedarf an die Speicherkapazitäten und Verlangsamen der Anfragebearbeitung führt. Dieses mögliche Problem des Event Stores wird dadurch gelöst, dass das Ergebnis eines Replays als Snapshot <sup>[13](#myfootnote13)</sup> realisiert und gespeichert wird. Der genannte Snapshot kann danach als Ausgangsbasis für die zukünftigen Anfragen dienen. Dadurch werden die Replays beschleunigt und es kommt zu keinem Performanceverlust.

In einer ausführlichen Recherche, bezüglich einer geeigneten Umsetzung der Ereignisverarbeitung im Rahmen des MISSION Projektes, wurden neben den von Greg Young entwickelten Event Store auch andere Alternativen betrachtet um eine fundierte Entscheidung treffen zu können. Wie bereits am Anfang des Kapitels beschrieben worden ist, eigenen sich relationale Datenbanken nicht, da es ein Ziel der Ereignisverarbeitung vergangene Events zu speichern. Aber auch im Vergleich zu anderen Datenbanksystemen, welche oft für Event Sourcing eingesetzt werden, bietet der Event Store mehrere Vorteile für das MISSION Projekt. Beispielsweise im Gegensatz zu Datomic  bietet der Event Store aufgrund des dynamischen Datenmodels die Möglichkeit vordefinierte Attribute umzubenennen und zu ändern. Diese Eigenschaft erlaubt eine flexible und zeiteffiziente Anpassung des früher festgelegten Datenmodels. Es kann von Nutzen und sinnvoll sein, wenn zum Beispiel ein neuer Inhalt und / oder eine neue Struktur des Events definiert wird. Außerdem ist Datomic nur ein Aufbau auf andere Datenbanken, was bedeutet, dass Datomic <sup>[14](#myfootnote14)</sup> selbst keine Daten speichert und sich mit anderen Datenbanken, wie relationale Datenbanken, verbinden muss. Dies erhöht die Komplexität des gesamten Systems und führt zu höheren Zeit- und Kostenaufwendungen. Des Weiteren erschwert es die Wartbarkeit des gesamten Systems. Eine solche Architektur besitzen ebenfalls andere ähnliche Datenbanken wie NEventStore <sup>[15](#myfootnote15)</sup> und SQLStreamStore <sup>[16](#myfootnote16)</sup>. Diese aufgelisteten Produkte sind nur Bibliotheken und verfügen über keine eigene Datenbankbasis. Neben den aufgelisteten Nachteilen führt die beschriebene Architektur dazu, dass die Performance (die Geschwindigkeit von Schreib- und Leseoperationen) sinkt.

Nachdem die Vorteile des Event Stores detailliert analysiert worden sind, ist es auch wichtig, die möglichen Nachteile aufzulisten. Und zwar ist die beschriebene Technologie eher für traditionelle Lösungen, in denen Daten in RDBMS gespeichert werden können, adäquat. Außerdem wurden Frameworks und Datenbanken für die Eventverarbeitung wie beispielsweise Apache Flink <sup>[17](#myfootnote17)</sup>, Kafka <sup>[18](#myfootnote18)</sup>, Spark <sup>[19](#myfootnote19)</sup> zunächst für die verteilten und / oder NoSQL Datenbanken betrachtet. Die Besonderheit der NoSQL Datenbanken im Vergleich zu den RDBMS ist, dass NoSQL Datenbanken basierend auf dem BASE Designprinzips entwickelt werden. Bei diesem Prinzip wird die Konsistenz der Verfügbarkeit untergeordnet. Da aber die Datenkonsistenz, im Rahmen des MISSION Projektes, ein wesentliches Ziel ist, bietet wiederum die Nutzung des Event Stores, für MISSION geeignete Vorteile.

Abschließend dieser Recherche ist es möglich die Aussage zu treffen, dass der Event Store sich für die Ziele der Ereignisverarbeitung im MISSION Projekt qualifiziert und die Anforderungen entsprechend umsetzt.  Der hohe Übereinstimmungsgrad mit dem im MISSION Projekt angewendeten Design und Pattern führt zu einem geeigneteren Verständnis der Event Services und erleichtert die Implementierung sowie die Integration ins das MISSION System.

<h4 id="1.2.3.4"> 1.2.3.4	Position des Event Service im gesamten MISSION System </h4>

Die Event Komponente ist ein wesentlicher Bestandteil des MISSION Systems um die Daten aktuell zu halten und Abläufe verfolgen zu können. Aus diesem Grund ist die Bestimmung der Position der Event Komponente im MISSION System sowie die Definition der Schnittstellen zu anderen Komponenten essentiell.

Anbieter in der MISSION Infrastruktur stellen anderen Nutzern der MISSION Infrastruktur Ereignisse aus ihrem System über die standardisierten Event Services zu Verfügung. Diese Event Services initiieren die Aktualisierung der internen Datenstrukturen, also die Graphdatenbank, des Routing Services, im genaueren die Komponente Routenupdates, auf Basis der im Event Service bereitgestellten Ereignisse (z.B. FahrplanUpdates). Die Event Services können auch beliebig vielen anderen Services, die im Laufe der Anwendungszeit in MISSION erstellt werden, Zugriff auf die Ereignisse bieten. Dementsprechend ist es notwendig eine API des Event Services für beliebig viele weitere Services anzubieten, wobei konkret der Fokus auf den Informationenaustausch mit der Komponente Routenupdates des Routing Services liegt, da dieser essentiell ist um die Aktualität der Routensuche gewährleisten zu können.

Des Weiteren ist die API zu dem Frontend für eine visuelle Darstellung in Form eines Dashboards, für den Anwender relevanten Events (transportplanabhängige Events und Fahrplanaktualisierungen), essentiell. Die Beschaffenheit dieser Darstellung der Event-Übersicht im Frontend liegt hierbei im Aufgabenbereich der UzL.

Der Event Service ist für die Koordination der Events zuständig, welche durch den Event Store erzeugt werden. Somit, und wie bereits aus [Kapitel 1.2.3.2](#1.2.3.2) hervorgehend, bildet das verteilte System des Event Stores die Basis der Event Komponente. Die Event Stores sind dezentral bei den angeschlossenen Anbietern positioniert, wodurch die Komplexität des Zentralsystems, insbesondere das Datenvolumen und als Folge dessen der Bedarf an Speicherkapazitäten, reduziert werden. Aufgrund dieser Anordnung handelt es sich bei der Event Komponente um ein verteiltes System, innerhalb des MISSION Gesamtsystems. Die dezentralen Event Stores werden entsprechende Services anbieten, welche die Events (Status und Fahrplanaktualisierung) im Form von Atom Feeds <sup>[20](#myfootnote20)</sup> zur Verfügung stellen.

Somit sind die wesentlichen Bestandteile der Eventverarbeitung der Event Service und ebenso die Event Stores und deren Services, auf die der Event Service mittels Kommunikation, bzw. Informationsbeschaffung durch die MISSION Infrastruktur zugreifen kann. Um dies realisieren zu können, müssen alle (angebotenen) Services in dem Service-Register der MISSION-Infrastruktur registriert sein und mittels Service-Discovery und Service-Identifikation auffindbar sein. Um einen Informationsaustausch mit dem Event Service und den Event Store Services aufbauen zu können, ist demnach auch eine API zu der MISSION Infrastruktur für die Services notwendig. Die technischen Konzepte hierfür gehören dem Aufgabenfeld von Fraunhofer CML an und werden für die weitere Entwicklung der Ereignisverarbeitung als vorhanden und funktionsfähig vorausgesetzt.

Um sicherzustellen, dass beispielsweise der Routing Service über eine Vielzahl aktueller Daten verfügt und die Daten aller angebotenen Services berücksichtigt, muss ein weiterer Event Store, intern in der MISSION Infrastruktur, eingerichtet werden. In diesem Event Store werden Events veröffentlicht, die über die neuangeschlossenen beziehungsweise neu registrierten Anbieter und deren Services informieren. Diese Hauptfunktionalität ist in Abbildung 1 dargestellt.

Detaillierte Analysen des Prozessablaufs der Ereignisverarbeitung, des Abonnierens von entsprechenden Services und der Synchronisation der verteilten Event Stores werden im Rahmen des AP: 320 Routing und Ereignisverarbeitung Services durchgeführt.
  
<h3 id="1.2.4"> 1.2.4	Funktionale und non-funktionale Anforderungen an MISSION System </h3>

Um die Qualität des gesamten Systems und der einzelnen Komponenten zu sichern und letztendlich ein qualitatives Produkt zu entwickeln, sollen die entsprechenden funktionalen und non-funktionalen Anforderungen an die Komponenten des MISSION Systems immer vor den Augen gehalten werden. In diesem Kapitel werden die Soll-Vorgaben zu den Services Routing und Events aus dem AP 200 konkretisiert. Die Erläuterung und Konkretisierung der Anforderungen spielt eine nicht zu unterschätzende Rolle in dieser Etappe des MISSION Projektes. Die klare und einheitliche Vorstellung bei den beteiligten am MISSION Projekt Partnern über das zu entwickelte System sowie über dessen qualitativen Merkmalen ist eine Voraussetzung für eine effiziente Zusammenarbeit.

<h4 id="1.2.4.1"> 1.2.4.1	Anforderungen an den Routing Service </h4>

Der Routing Service hat eine wichtige Position im gesamten MISSION System. Wie es schon bereits im Rahmen des AP 200 erwähnt wurde, sollen die folgenden technischen Aspekte bei der Entwicklung der genannten Services betrachtet werden:

1.	Verfügbarkeit  
2.	Sicherheit  
3.	Performance  
4.	Flexibilität und  
5.	Skalierbarkeit.

In den vorherigen Kapiteln wurde bereits darauf hingewiesen, dass der Aspekt der hohen Verfügbarkeit des Routing Service (im Sinne vom Informations- und Routensuchen Services) gewährleistet wird durch die existierenden internen Datenaustauschkanäle. Um dies zu erreichen, muss eine Zusammenarbeit mit den entsprechenden Entwicklungsteams stattfinden. Als Ergebnis muss eine gemeinsame Lösung gefunden werden, die als Fundament des MISSION Konzeptes dient. Die hohe Performance des Routing Service wird durch die ausgewählte Graphendatenbank Neo4j gesichert, welche es erlaubt die benötigen Routenberechnungen in Echtzeit durchzuführen. Außerdem ermöglicht die beschriebene Datenbank, durch die dynamischen Datenschemata, eine geeignete sowie effiziente Anpassbarkeit und Erweiterbarkeit des Systems und der Daten an die neuen Anforderungen und Änderungen, was unter die Anforderungen Flexibilität und Skalierbarkeit zusammengefasst wurde.

<h4 id="1.2.4.2"> 1.2.4.2	Anforderungen an die Event Services </h4>

Die im vorherigen [Kapitel 1.2.4.1](#1.2.4.1) aufgelisteten Anforderungen - Verfügbarkeit, Sicherheit, Performance, Flexibilität und Skalierbarkeit - gelten ebenfalls für die Services der Events.

Zunächst ist es wichtig darauf hinzuweisen, dass einerseits die fachlichen Ereignisse als eine relativ kleine Datenmenge realisiert werden können, anderseits es sich in der Praxis um Ereignis-Ströme (oder Event-Streaming) handelt. Das heißt in dem relativ geringen Zeitabstand wird die gesamte Menge von Ereignissen erstellt und an das entsprechende System übergeben. Aufgrund der hohen Geschwindigkeit und der Anzahl der Events spielt die Verfügbarkeit der Event Services eine führende Rolle. Deshalb muss die zu implementierende Datenbank die Möglich-keit bieten Events kontinuierlich abfragen und schreiben zu können. Diese Verfügbarkeit des Ereignisverarbeitungs-Services wird durch die bereits beschriebene funktionale Datenbank Event Store realisiert, welche ebenfalls eine hohe Performance gewährleistet (15000 – 20000 Schreibzugriffen pro Sekunde mit TCP Protokoll und 2000 Schreibzugriffen pro Sekunde mit HTTP Protokoll). Darüber hinaus werden die Verfügbarkeit und die Performance des Service, durch den Einsatz des Command-Query-Responsibility-Segregation Patterns (kurz CQRS-Pattern), erhöht. Darunter ist zu verstehen, dass Methoden nur als Abfragen oder als Kommandos realisiert werden können. Die beschriebene strikte Trennung der verwendeten Methoden führt zu einer klaren und performanten Bearbeitung der Methoden. Außer der Erhöhung der Performance verbessert das CQRS-Pattern die Sicherheit des Systems, durch die separierten Rollen der Schreib- und Leseoperationen. Die bereits vorab beschriebene Append-Only-Architektur des Event Stores kann bezüglich der vordefinierten Anforderungen auch als einen Vorteil gesehen werden. Diese Architektur kann in der Praxis einfacher im Vergleich zu den klassischen Datenbanken mit der Update-Architektur verteilt und skaliert werden <sup>[21](#myfootnote21)</sup>. Dadurch müssen weniger Abgrenzungen und Ausnahmen bei der Append-Only-Architektur berücksichtigt werden. Die hohe Skalierbarkeit, Flexibilität und Erweiterung des Event Stores werden auch mithilfe der horizontalen Partitionierung erreicht. Das bedeutet, dass dasselbe Schema an vielen Stellen existieren kann und dass ein Schlüssel innerhalb der Daten (bei Events handelt es sich um UUID) bestimmt, an welche Stelle (bei welchem Unternehmen) die Daten existieren.

Diese bereits beschriebenen Besonderheiten von Event Store spielen eine führende Rolle im Rahmen des MISSION Projekt aufgrund der hochverteilten Architektur der Event Komponente.

<h2 id="1.3"> 1.3 Anwendungen </h2>

<h2 id="1.4"> 1.4	Zusammenspiel der Komponenten </h2>

<h3 id="1.4.1"> 1.4.1	Dienste werden in Infrastruktur registriert </h3>

/* (Erst später beschreiben) */

/* Wie bereits im Kapitel X erwähnt wurde, ist es notwendig, dass alles Services, bzw. Dienste, sich in der Infrastruktur bekannt machen, also registrieren, damit sie von andern Nutzern oder Services angewendet werden können. Die Serviceregistrierung und das Identitätsregister sind die Komponenten der MISSION Infrastruktur, die für diese Registrierung zuständig sind. Das Ziel dieser Registrierung der Services ist es, die Services für andere Services und Nutzer bekannt zu machen, sodass sie von diesen verwendet werden können. Um die Services zu verwenden ist es essentiell, dass die Services die Lokation voneinander um miteinander interagieren zu können…*/

Hier beschreiben/voraussetzen, dass bei Service-Registrierung die Services Routing/Event über einen neuen Service informiert werden sollen, um z.B. Fahrpläne eines  neu registrierten Verkehrsträgers abzuholen.

<h3 id="1.4.2"> 1.4.2	Anwendungen finden Dienste über Infrastruktur </h3>

<h3 id="1.4.3"> 1.4.3	Anwendungen nutzen Dienste </h3>

Hier die Kommunikation mit GUI über API beschreiben und Prozessmodelle aus AP300 in JIRA einfügen.


<a name="myfootnote1">1</a>: Krafzig D., Banke K. und Slama D. (2005): Enterprise SOA. Service-Oriented Architecture. Best Practices. USA: Pearson Education, Inc. (s. 68, 242-250).

<a name="myfootnote2">2</a>: Landre W., Wesenberg H. und Olmheim J. (2007): Agile Enterprise Software Development Using Domain-Driven Design and Test First. Knada: OOPSLA ’07 (s. 990-991).

<a name="myfootnote3">3</a>: www.neo4j.com

<a name="myfootnote4">4</a>: Robinson I., Webber J. und Eifre, E. (2015): Graph Databases. New opportunities for connected data. Second Edition. USA: O’Reilly (s. 95-97).

<a name="myfootnote5">5</a>: Robinson I., Webber J. und Eifre, E. (2015): Graph Databases. New opportunities for connected data. Second Edition. USA: O’Reilly (s. 8, 21).

<a name="myfootnote6">6</a>: https://neo4j.com/developer/language-guides/

<a name="myfootnote7">7</a>: www.ibm.com/de-de/marketplace/graph/purchase#product-header-top

<a name="myfootnote8">8</a>: Robinson, Ian, Jim Webber and Emil Eifrem. Graph databases. “O’Reilly Media, Inc.”, S. 1-4, 2013.

<a name="myfootnote9">9</a>: Powers, Shelley. Practical RDF: solving problems with the resource description framework.” O’Reilly Media, Inc.”, S. 19-21, 2003.

<a name="myfootnote10">10</a>: Robinson, Ian, Jim Webber and Emil Eifrem. Graph databases. “O’Reilly Media, Inc.”, S. 207, 2013.

<a name="myfootnote11">11</a>: www.neo4j.com/blog/neo4j-3-0-massive-scale-developer-productivity/

<a name="myfootnote12">12</a>: www.neo4j.com/developer/cypher-query-language/

<a name="myfootnote13">13</a>: www.eventstore.org/docs/event-sourcing-basics/rolling-snapshots/index.html

<a name="myfootnote14">14</a>: www.datomic.com

<a name="myfootnote15">15</a>: www.github.com/NEventStore/NEventStore/wiki/Architectural-Overview

<a name="myfootnote16">16</a>: www.sqlstreamstore.readthedocs.io/en/latest/

<a name="myfootnote17">17</a>: www.flink.apache.org

<a name="myfootnote18">18</a>: www.kafka.apache.org

<a name="myfootnote19">19</a>: www.spark.apache.org

<a name="myfootnote20">20</a>: https://tools.ietf.org/html/rfc4287

<a name="myfootnote21">21</a>: www.eventstore.org/docs/event-sourcing-basics/performance-and-scaling/index.html
